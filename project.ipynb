{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eroQ5J_wBQQh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "import random\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Flatten, Dense,\\\n",
        "                                    Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.metrics import Mean, CosineSimilarity\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB7, preprocess_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxBktst0yfgb"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import shutil\n",
        "\n",
        "# Define the path to the new directory\n",
        "new_dir_path = \"/content/input\"\n",
        "\n",
        "# Check if the directory already exists\n",
        "if not os.path.exists(new_dir_path):\n",
        "    # If the directory doesn't exist, create it\n",
        "    os.makedirs(new_dir_path)\n",
        "    print(f\"Directory '{new_dir_path}' created successfully!\")\n",
        "else:\n",
        "    print(f\"Directory '{new_dir_path}' already exists!\")\n",
        "\n",
        "# Copy Face Data.rar\n",
        "shutil.copy2('/content/drive/MyDrive/Face Data.rar', '/content/input/Face Data.rar')\n",
        "\n",
        "# Copy Extracted Faces.zip\n",
        "shutil.copy2('/content/drive/MyDrive/Extracted Faces.zip', '/content/input/Extracted Faces.zip')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DimNe6DBB0OL"
      },
      "outputs": [],
      "source": [
        "!pip install rarfile\n",
        "\n",
        "print(\"Current working directory:\", os.getcwd())\n",
        "\n",
        "import zipfile\n",
        "from rarfile import RarFile\n",
        "\n",
        "face_data_rar_file = './input/Face Data.rar'\n",
        "extracted_faces_zip_file = './input/Extracted Faces.zip'\n",
        "\n",
        "extract_to = './input/'\n",
        "\n",
        "with zipfile.ZipFile(extracted_faces_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "with RarFile(face_data_rar_file, 'r') as rar_ref:\n",
        "    rar_ref.extractall(extract_to)\n",
        "\n",
        "extracted_files = os.listdir(extract_to)\n",
        "print(f\"Extracted files: {extracted_files}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKL3XJYvSHxN"
      },
      "outputs": [],
      "source": [
        "FACE_DATA_PATH = './input/Face Dataset'\n",
        "EXTRACTED_FACES_PATH = './input/Extracted Faces'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4SwWSsKFPcd"
      },
      "outputs": [],
      "source": [
        "def explore_folder(folder_path):\n",
        "    print(f'Exploring {os.path.basename(folder_path)}')\n",
        "    image_shapes = []\n",
        "    num_images = 0\n",
        "    num_people = 0\n",
        "    for folder_name in os.listdir(folder_path):\n",
        "        subfolder_path = os.path.join(folder_path, folder_name)\n",
        "        for image_name in os.listdir(subfolder_path):\n",
        "            image_path = os.path.join(subfolder_path, image_name)\n",
        "            image = cv2.imread(image_path)\n",
        "            image_shapes.append(image.shape)\n",
        "            num_images += 1\n",
        "        num_people +=1\n",
        "    print(f'Unique image shapes in: {set(image_shapes)}')\n",
        "    print(f\"Total number of images: {num_images}\")\n",
        "    print(f\"Total number of people: {num_people}\")\n",
        "    return image_shapes, num_images, num_people"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyY_IAuzFU7u"
      },
      "outputs": [],
      "source": [
        "explore_folder(FACE_DATA_PATH);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNOw77gLUuXg"
      },
      "outputs": [],
      "source": [
        "explore_folder(EXTRACTED_FACES_PATH);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWKl9agiWeIm"
      },
      "outputs": [],
      "source": [
        "def visualize_sample_images(folder_path):\n",
        "    num_images = len(os.listdir(folder_path))\n",
        "    num_rows = (num_images + 4) // 5\n",
        "    num_cols = min(num_images, 5)\n",
        "\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(10, 3 * num_rows))\n",
        "\n",
        "    for i, image_name in enumerate(os.listdir(folder_path)):\n",
        "        image_path = os.path.join(folder_path, image_name)\n",
        "        sample_image = cv2.imread(image_path)\n",
        "        sample_image = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        row = i // num_cols\n",
        "        col = i % num_cols\n",
        "        ax = axes[row, col] if num_rows > 1 else axes[col]\n",
        "\n",
        "        ax.imshow(sample_image)\n",
        "        ax.axis('off')\n",
        "\n",
        "    for ax in axes.flat[num_images:]:\n",
        "        ax.remove()\n",
        "\n",
        "    plt.suptitle(f'Person ID: {os.path.basename(folder_path)}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzCrhayvXPdH"
      },
      "outputs": [],
      "source": [
        "person_id = random.choice(os.listdir(FACE_DATA_PATH))\n",
        "folder_path = os.path.join(FACE_DATA_PATH, person_id)\n",
        "\n",
        "print(f'Samples from {os.path.basename(FACE_DATA_PATH)}')\n",
        "\n",
        "visualize_sample_images(folder_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxew4xxtPpIR"
      },
      "outputs": [],
      "source": [
        "print(f'Samples from {os.path.basename(EXTRACTED_FACES_PATH)}')\n",
        "\n",
        "if person_id in os.listdir(EXTRACTED_FACES_PATH):\n",
        "    folder_path = os.path.join(EXTRACTED_FACES_PATH, person_id)\n",
        "    visualize_sample_images(folder_path)\n",
        "else:\n",
        "    print(f'There is no person {person_id} in this folder')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_PWtCf-NNtw"
      },
      "outputs": [],
      "source": [
        "# create dataset\n",
        "import shutil\n",
        "DATASET = './images/output_dataset'\n",
        "\n",
        "if os.path.exists(DATASET):\n",
        "    shutil.rmtree(DATASET)\n",
        "\n",
        "os.makedirs(DATASET)\n",
        "\n",
        "def copy_to_output_dataset(input_path, output_path):\n",
        "    for person_folder in os.listdir(input_path):\n",
        "        person_folder_path = os.path.join(input_path, person_folder)).\n",
        "\n",
        "        if os.path.isdir(person_folder_path):\n",
        "            output_person_folder = os.path.join(output_path, person_folder)\n",
        "            if not os.path.exists(output_person_folder):\n",
        "                os.makedirs(output_person_folder)\n",
        "\n",
        "            for image_file in os.listdir(person_folder_path):\n",
        "                if image_file.endswith('.jpg'):\n",
        "                    src_image_path = os.path.join(person_folder_path, image_file)\n",
        "                    dst_image_path = os.path.join(output_person_folder, image_file)\n",
        "                    if os.path.exists(dst_image_path):\n",
        "                        base, ext = os.path.splitext(dst_image_path)\n",
        "                        dst_image_path = f\"{base}_1{ext}\"\n",
        "\n",
        "                    shutil.copy(src_image_path, dst_image_path)\n",
        "\n",
        "copy_to_output_dataset(FACE_DATA_PATH, DATASET)\n",
        "\n",
        "copy_to_output_dataset(EXTRACTED_FACES_PATH, DATASET)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G54ilbxbQGrl"
      },
      "outputs": [],
      "source": [
        "explore_folder(DATASET);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fypLS2Q1QfSP"
      },
      "outputs": [],
      "source": [
        "visualize_sample_images(os.path.join(DATASET, '500'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkeGB-jCuot-"
      },
      "outputs": [],
      "source": [
        "visualize_sample_images(os.path.join(DATASET, '1500'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFP-ap3da-to"
      },
      "outputs": [],
      "source": [
        "def triplets(folder_paths, max_triplets=7):\n",
        "    anchor_images = []\n",
        "    positive_images = []\n",
        "    negative_images = []\n",
        "\n",
        "    for person_folder in folder_paths:\n",
        "        images = [os.path.join(person_folder, img) for img in os.listdir(person_folder)]\n",
        "        num_images = len(images)\n",
        "        if num_images < 2:\n",
        "            continue\n",
        "\n",
        "        random.shuffle(images)\n",
        "\n",
        "        for _ in range(max(num_images - 1, max_triplets)):\n",
        "            # select the anchor randomly\n",
        "            anchor_image = random.choice(images)\n",
        "            # select the positive randomly, excluding the anchor\n",
        "            positive_image = random.choice([x for x in images if x != anchor_image])\n",
        "            # select the negative randomly, excluding the anchor\n",
        "            negative_folder = random.choice([x for x in folder_paths if x != person_folder])\n",
        "            negative_image = random.choice([os.path.join(negative_folder, img)\n",
        "                                            for img in os.listdir(negative_folder)])\n",
        "\n",
        "            anchor_images.append(anchor_image)\n",
        "            positive_images.append(positive_image)\n",
        "            negative_images.append(negative_image)\n",
        "\n",
        "    return anchor_images, positive_images, negative_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIlcvVhxclUV"
      },
      "outputs": [],
      "source": [
        "person_folders = [os.path.join(DATASET, folder_name)\n",
        "                  for folder_name in os.listdir(DATASET)]\n",
        "\n",
        "anchors, positives, negatives = triplets(person_folders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVzFoF14dTb7"
      },
      "outputs": [],
      "source": [
        "def split_triplets(anchors, positives, negatives, validation_split=0.2):\n",
        "    triplets = list(zip(anchors, positives, negatives))\n",
        "\n",
        "    train_triplets, val_triplets = train_test_split(triplets,\n",
        "                                                    test_size=validation_split,\n",
        "                                                    random_state=42)\n",
        "\n",
        "    return train_triplets, val_triplets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWFmVTjed6G3"
      },
      "outputs": [],
      "source": [
        "train_triplets, val_triplets = split_triplets(anchors,\n",
        "                                              positives,\n",
        "                                              negatives)\n",
        "len(train_triplets), len(val_triplets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2wSNJ9EePZW"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_image(image_path, expand_dims=False):\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Error reading image from path: {image_path}\")\n",
        "\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, (128, 128))\n",
        "\n",
        "    if expand_dims:\n",
        "        image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4mInrtAQcXb"
      },
      "outputs": [],
      "source": [
        "# balance data and generator batch\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, precision_score, recall_score, f1_score, classification_report\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "\n",
        "def balance_data(train_triplets):\n",
        "    anchors, positives, negatives = zip(*train_triplets)\n",
        "    labels = [1] * len(positives) + [0] * len(negatives)\n",
        "    data = list(zip(anchors + anchors, positives + negatives))\n",
        "\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "    data_resampled, labels_resampled = ros.fit_resample(data, labels)\n",
        "    anchors_resampled, positives_negatives_resampled = zip(*data_resampled)\n",
        "    positives_resampled = [pn for pn, l in zip(positives_negatives_resampled, labels_resampled) if l == 1]\n",
        "    negatives_resampled = [pn for pn, l in zip(positives_negatives_resampled, labels_resampled) if l == 0]\n",
        "\n",
        "    return list(zip(anchors_resampled[:len(positives_resampled)], positives_resampled, negatives_resampled))\n",
        "\n",
        "def batch_generator(triplets, batch_size=32, augment=True):\n",
        "    triplets = balance_data(triplets)\n",
        "    total_triplets = len(triplets)\n",
        "    random_indices = list(range(total_triplets))\n",
        "    random.shuffle(random_indices)\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=10,\n",
        "        width_shift_range=0.05,\n",
        "        height_shift_range=0.05,\n",
        "        horizontal_flip=True,\n",
        "        zoom_range=0.2\n",
        "    )\n",
        "\n",
        "    for i in range(0, total_triplets, batch_size):\n",
        "        batch_indices = random_indices[i:i + batch_size]\n",
        "        batch_triplets = [triplets[j] for j in batch_indices]\n",
        "\n",
        "        anchor_batch = []\n",
        "        positive_batch = []\n",
        "        negative_batch = []\n",
        "\n",
        "        for triplet in batch_triplets:\n",
        "            anchor, positive, negative = triplet\n",
        "            anchor_image = load_and_preprocess_image(anchor)\n",
        "            positive_image = load_and_preprocess_image(positive)\n",
        "            negative_image = load_and_preprocess_image(negative)\n",
        "\n",
        "            if augment:\n",
        "                anchor_image = datagen.random_transform(anchor_image)\n",
        "                positive_image = datagen.random_transform(positive_image)\n",
        "                negative_image = datagen.random_transform(negative_image)\n",
        "\n",
        "            anchor_batch.append(anchor_image)\n",
        "            positive_batch.append(positive_image)\n",
        "            negative_batch.append(negative_image)\n",
        "\n",
        "        yield [np.array(anchor_batch), np.array(positive_batch), np.array(negative_batch)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtuYGRhsfslj"
      },
      "outputs": [],
      "source": [
        "def visualize_triplets(triplets):\n",
        "  anchor_batch, positive_batch, negative_batch = triplets\n",
        "\n",
        "  for i in range(len(anchor_batch)):\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.title(\"Anchor\")\n",
        "    plt.imshow(anchor_batch[i])\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.title(\"Positive\")\n",
        "    plt.imshow(positive_batch[i])\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.title(\"Negative\")\n",
        "    plt.imshow(negative_batch[i])\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAZ1Gkj4f6bn"
      },
      "outputs": [],
      "source": [
        "example_triplets = [next(batch_generator(train_triplets, 5))]\n",
        "visualize_triplets(example_triplets[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRe_pHJkghyS"
      },
      "outputs": [],
      "source": [
        "def get_embedding(input_shape, num_layers_to_unfreeze=25):\n",
        "  base_model = EfficientNetB7(\n",
        "      weights='imagenet',  # Load pre-trained weights\n",
        "      input_shape=input_shape,  # Specify input shape\n",
        "      include_top=False,  # Exclude the top classification layers\n",
        "      pooling='avg'  # Use average pooling for feature extraction\n",
        "  )\n",
        "\n",
        "  for i in range(len(base_model.layers) - num_layers_to_unfreeze):\n",
        "    base_model.layers[i].trainable = False\n",
        "\n",
        "  embedding = tf.keras.models.Sequential([\n",
        "      base_model,\n",
        "      Flatten(),\n",
        "      Dense(512, activation='relu'),\n",
        "      BatchNormalization(),\n",
        "      Dropout(0.3),\n",
        "      Dense(256, activation='relu'),\n",
        "      BatchNormalization(),\n",
        "      Dropout(0.3),\n",
        "      Dense(128, activation='relu'),\n",
        "      BatchNormalization(),\n",
        "      Dense(128)\n",
        "  ], name='Embedding')\n",
        "\n",
        "  return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZdzSdSLgm4D"
      },
      "outputs": [],
      "source": [
        "input_shape = (128, 128, 3)\n",
        "\n",
        "embedding = get_embedding(input_shape)\n",
        "embedding.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvIgKaoJitxA"
      },
      "outputs": [],
      "source": [
        "@tf.keras.saving.register_keras_serializable()\n",
        "class DistanceLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def call(self, anchor, positive, negative):\n",
        "        ap_distance = tf.reduce_sum(tf.square(anchor - positive), -1)\n",
        "        an_distance = tf.reduce_sum(tf.square(anchor - negative), -1)\n",
        "        return ap_distance, an_distance\n",
        "\n",
        "anchor_input = Input(name='anchor', shape=input_shape)\n",
        "positive_input = Input(name='positive', shape=input_shape)\n",
        "negative_input = Input(name='negative', shape=input_shape)\n",
        "\n",
        "distances = DistanceLayer()(\n",
        "    embedding(preprocess_input(anchor_input)),\n",
        "    embedding(preprocess_input(positive_input)),\n",
        "    embedding(preprocess_input(negative_input))\n",
        ")\n",
        "\n",
        "siamese_net = Model(\n",
        "    inputs=[anchor_input,\n",
        "            positive_input,\n",
        "            negative_input],\n",
        "    outputs=distances\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cu8a5Y4KjNpB"
      },
      "outputs": [],
      "source": [
        "plot_model(siamese_net, show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tNsicMojSwi"
      },
      "outputs": [],
      "source": [
        "siamese_net.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-QsyaJmkNUy"
      },
      "outputs": [],
      "source": [
        "@tf.keras.saving.register_keras_serializable()\n",
        "class SiameseModel(Model):\n",
        "    def __init__(self, siamese_net, margin=0.5):\n",
        "        super().__init__()\n",
        "        self.siamese_net = siamese_net\n",
        "        self.margin = margin\n",
        "        self.loss_tracker = Mean(name='loss')\n",
        "        self.accuracy_tracker = Mean(name='accuracy')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.siamese_net(inputs)\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = self._compute_loss(data)\n",
        "\n",
        "        gradients = tape.gradient(loss, self.siamese_net.trainable_weights)\n",
        "\n",
        "        self.optimizer.apply_gradients(\n",
        "            zip(gradients, self.siamese_net.trainable_weights)\n",
        "        )\n",
        "\n",
        "        self.loss_tracker.update_state(loss)\n",
        "\n",
        "        accuracy = self._compute_accuracy(data)\n",
        "        self.accuracy_tracker.update_state(accuracy)\n",
        "\n",
        "        return {'loss': self.loss_tracker.result(),\n",
        "                'accuracy': self.accuracy_tracker.result()}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        loss = self._compute_loss(data)\n",
        "\n",
        "        self.loss_tracker.update_state(loss)\n",
        "\n",
        "        accuracy = self._compute_accuracy(data)\n",
        "        self.accuracy_tracker.update_state(accuracy)\n",
        "\n",
        "        return {'loss': self.loss_tracker.result(),\n",
        "                'accuracy': self.accuracy_tracker.result()}\n",
        "\n",
        "    def _compute_loss(self, data):\n",
        "        ap_distance, an_distance = self.siamese_net(data)\n",
        "\n",
        "        loss = ap_distance - an_distance\n",
        "        loss = tf.maximum(loss + self.margin, .0)\n",
        "        return loss\n",
        "\n",
        "    def _compute_accuracy(self, data):\n",
        "        ap_distance, an_distance = self.siamese_net(data)\n",
        "        accuracy = tf.reduce_mean(tf.cast(ap_distance < an_distance,\n",
        "                                          tf.float32))\n",
        "        return accuracy\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker, self.accuracy_tracker]\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        config = {\n",
        "            'siamese_net': tf.keras.saving.serialize_keras_object(self.siamese_net),\n",
        "            'margin': tf.keras.saving.serialize_keras_object(self.margin),\n",
        "            'loss_tracker': tf.keras.saving.serialize_keras_object(self.loss_tracker),\n",
        "            'accuracy_tracker': tf.keras.saving.serialize_keras_object(self.accuracy_tracker),\n",
        "        }\n",
        "        return {**base_config, **config}\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        config['siamese_net'] = tf.keras.saving.deserialize_keras_object(config.pop('siamese_net'))\n",
        "        config['margin'] = tf.keras.saving.deserialize_keras_object(config.pop('margin'))\n",
        "        config['loss_tracker'] = tf.keras.saving.deserialize_keras_object(config.pop('loss_tracker'))\n",
        "        config['accuracy_tracker'] = tf.keras.saving.deserialize_keras_object(config.pop('accuracy_tracker'))\n",
        "        return cls(**config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbW0CF7BQ0uu"
      },
      "outputs": [],
      "source": [
        "def train_model(model,\n",
        "                train_triplets,\n",
        "                epochs,\n",
        "                batch_size,\n",
        "                val_triplets,\n",
        "                patience,\n",
        "                delta=0.0001):\n",
        "\n",
        "    best_val_accuracy = 0\n",
        "    best_val_loss = float('inf')\n",
        "    temp_patience = patience\n",
        "    history = {\n",
        "        'loss': [],\n",
        "        'val_loss': [],\n",
        "        'accuracy': [],\n",
        "        'val_accuracy': []\n",
        "    }\n",
        "\n",
        "    train_steps_per_epoch = math.ceil(len(train_triplets) / batch_size)\n",
        "    val_steps_per_epoch = math.ceil(len(val_triplets) / batch_size)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f'Epoch {epoch+1}/{epochs}')\n",
        "        train_loss = 0.\n",
        "        train_accuracy = 0.\n",
        "        val_loss = 0.\n",
        "        val_accuracy = 0.\n",
        "\n",
        "        with tqdm(total=train_steps_per_epoch, desc='Training') as pbar:\n",
        "            for batch in batch_generator(train_triplets, batch_size=batch_size):\n",
        "                loss, accuracy = model.train_on_batch(batch)\n",
        "                train_loss += loss\n",
        "                train_accuracy += accuracy\n",
        "\n",
        "                pbar.update()\n",
        "                pbar.set_postfix({'Loss': loss, 'Accuracy': accuracy})\n",
        "\n",
        "        with tqdm(total=val_steps_per_epoch, desc='Validation') as pbar:\n",
        "            for batch in batch_generator(val_triplets, batch_size=batch_size):\n",
        "                loss, accuracy = model.test_on_batch(batch)\n",
        "                val_loss += loss\n",
        "                val_accuracy += accuracy\n",
        "\n",
        "                pbar.update()\n",
        "                pbar.set_postfix({'Loss': loss, 'Accuracy': accuracy})\n",
        "\n",
        "        train_loss /= train_steps_per_epoch\n",
        "        train_accuracy /= train_steps_per_epoch\n",
        "        val_loss /= val_steps_per_epoch\n",
        "        val_accuracy /= val_steps_per_epoch\n",
        "\n",
        "        history['loss'].append(train_loss)\n",
        "        history['accuracy'].append(train_accuracy)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_accuracy'].append(val_accuracy)\n",
        "\n",
        "        print(f'\\nTrain Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}')\n",
        "        print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\\n')\n",
        "\n",
        "\n",
        "        if val_accuracy > best_val_accuracy and val_loss < best_val_loss:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            best_val_loss = val_loss\n",
        "            model.layers[0].layers[3].save_weights('best_model.weights.h5')\n",
        "\n",
        "        if val_loss - best_val_loss > delta:\n",
        "            temp_patience -= 1\n",
        "            if temp_patience == 0:\n",
        "                print('Early stopping: Validation loss did not improve.')\n",
        "                break\n",
        "        else:\n",
        "            best_val_loss = val_loss\n",
        "            temp_patience = patience\n",
        "\n",
        "    return model, history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lh8QHahhlMNR"
      },
      "outputs": [],
      "source": [
        "siamese_model = SiameseModel(siamese_net)\n",
        "siamese_model.compile(optimizer=Adam(0.001))\n",
        "\n",
        "siamese_model, history = train_model(siamese_model,\n",
        "                                     train_triplets=train_triplets,\n",
        "                                     epochs=200,\n",
        "                                     batch_size=128,\n",
        "                                     val_triplets=val_triplets,\n",
        "                                     patience=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAJNctuImFQS"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.plot(history['loss'])\n",
        "plt.plot(history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['TRAIN', 'VAL'], loc='lower right')\n",
        "\n",
        "plt.subplot(122)\n",
        "plt.plot(history['accuracy'])\n",
        "plt.plot(history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['TRAIN', 'VAL'], loc='lower right')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKtK3b74nHyz"
      },
      "outputs": [],
      "source": [
        "sample = next(batch_generator(val_triplets, 10))\n",
        "anchor, positive, negative = sample\n",
        "\n",
        "preprocessed_anchor = preprocess_input(anchor)\n",
        "preprocessed_positive = preprocess_input(positive)\n",
        "preprocessed_negative = preprocess_input(negative)\n",
        "\n",
        "anchor_embedding = embedding(preprocessed_anchor)\n",
        "positive_embedding = embedding(preprocessed_positive)\n",
        "negative_embedding = embedding(preprocessed_negative)\n",
        "\n",
        "cosine_similarity = CosineSimilarity()\n",
        "\n",
        "positive_similarity = cosine_similarity(anchor_embedding, positive_embedding)\n",
        "print(f\"positive_similarity: {positive_similarity}\")\n",
        "\n",
        "negative_similarity = cosine_similarity(anchor_embedding, negative_embedding)\n",
        "print(f\"negative_similarity: {negative_similarity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9kaxFU0F5O9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_confusion_matrix(model, val_triplets):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for batch in batch_generator(val_triplets, batch_size=1, augment=False):\n",
        "        ap_distance, an_distance = model.predict_on_batch(batch)\n",
        "        y_true.append(1)\n",
        "        y_true.append(0)\n",
        "        y_pred.append(1 if ap_distance < an_distance else 0)\n",
        "        y_pred.append(0 if ap_distance < an_distance else 1)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt='d')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()\n",
        "plot_confusion_matrix(siamese_model, val_triplets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkw5Caq5mWOd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "\n",
        "def compute_roc_auc(model, val_triplets):\n",
        "    y_true = []\n",
        "    y_scores = []\n",
        "\n",
        "    for batch in batch_generator(val_triplets, batch_size=1, augment=False):\n",
        "        ap_distance, an_distance = model.predict_on_batch(batch)\n",
        "\n",
        "        # true label：1 is positive sample，0 is negative sample\n",
        "        y_true.append(1)\n",
        "        y_scores.append(-ap_distance)  # Negative distance means higher similarity\n",
        "        y_true.append(0)\n",
        "        y_scores.append(-an_distance)\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    return fpr, tpr, roc_auc\n",
        "\n",
        "def plot_roc_curve(fpr, tpr, roc_auc):\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "fpr, tpr, roc_auc = compute_roc_auc(siamese_model, val_triplets)\n",
        "print(f\"AUC: {roc_auc}\")\n",
        "\n",
        "plot_roc_curve(fpr, tpr, roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuFYnxTzniQR"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "mse = mean_squared_error(anchor_embedding, positive_embedding)\n",
        "print(f\"Mean Squared Error between Anchor and Positive: {mse}\")\n",
        "\n",
        "mse = mean_squared_error(anchor_embedding, negative_embedding)\n",
        "print(f\"Mean Squared Error between Anchor and Negative: {mse}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDGQZjMlnl9Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.metrics import CosineSimilarity\n",
        "from tensorflow.keras.models import load_model\n",
        "from google.colab import files\n",
        "\n",
        "def load_and_preprocess_image(image_path, target_size=(128, 128)):\n",
        "    img = image.load_img(image_path, target_size=target_size)\n",
        "    img_array = image.img_to_array(img)\n",
        "    return preprocess_input(img_array)\n",
        "\n",
        "def prepare_image(image_path):\n",
        "    preprocessed_query_image = load_and_preprocess_image(image_path)\n",
        "    preprocessed_query_image = np.expand_dims(preprocessed_query_image, axis=0)\n",
        "    return preprocess_input(preprocessed_query_image)\n",
        "\n",
        "def get_embedding(input_shape, num_layers_to_unfreeze=25):\n",
        "    base_model = tf.keras.applications.EfficientNetB7(\n",
        "        weights='imagenet',\n",
        "        input_shape=input_shape,\n",
        "        include_top=False,\n",
        "        pooling='avg'\n",
        "    )\n",
        "\n",
        "    for i in range(len(base_model.layers) - num_layers_to_unfreeze):\n",
        "        base_model.layers[i].trainable = False\n",
        "\n",
        "    embedding = tf.keras.models.Sequential([\n",
        "        base_model,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(128, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dense(128)\n",
        "    ], name='Embedding')\n",
        "\n",
        "    return embedding\n",
        "\n",
        "def find_matching_images(directory_path, model_weights_path='best_model.weights.h5', threshold=0.5):\n",
        "    input_shape = (128, 128, 3)\n",
        "    embedding = get_embedding(input_shape)\n",
        "    embedding.load_weights(model_weights_path)\n",
        "\n",
        "    for folder_name in os.listdir(directory_path):\n",
        "        print(folder_name)\n",
        "        subfolder_path = os.path.join(directory_path, folder_name)\n",
        "        query_image_folder = os.path.join(subfolder_path, \"query\")\n",
        "        query_image_name = os.listdir(query_image_folder)[0]\n",
        "        query_image_path = os.path.join(query_image_folder, query_image_name)\n",
        "        datasets_path = os.path.join(subfolder_path, \"support\")\n",
        "\n",
        "        query_image = prepare_image(query_image_path)\n",
        "        query_embedding = embedding.predict(query_image)\n",
        "\n",
        "        cosine_similarity = CosineSimilarity()\n",
        "        best_match = None\n",
        "        best_similarity = -1\n",
        "\n",
        "        for image_name in os.listdir(datasets_path):\n",
        "            image_path = os.path.join(datasets_path, image_name)\n",
        "\n",
        "            if image_path.endswith(\".jpg\"):\n",
        "                support_image = prepare_image(image_path)\n",
        "                support_embedding = embedding.predict(support_image)\n",
        "\n",
        "                similarity = cosine_similarity(query_embedding, support_embedding)\n",
        "\n",
        "                if similarity > best_similarity:\n",
        "                    best_similarity = similarity\n",
        "                    best_match_path = image_path\n",
        "\n",
        "        if best_similarity >= threshold:\n",
        "            print(f\"Similarity: {best_similarity}\")\n",
        "            print(f\"Query Image Path: {query_image_path}\")\n",
        "            print(f\"Best match Path: {best_match_path}\")\n",
        "            fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
        "            fig.suptitle(\"Query Image and Best Match\")\n",
        "            axs[0].imshow(plt.imread(query_image_path))\n",
        "            axs[0].set_title(\"Query Image\")\n",
        "            axs[1].imshow(plt.imread(best_match_path))\n",
        "            axs[1].set_title(\"Best Match\")\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"No match found\")\n",
        "\n",
        "def upload_and_test(model_weights_path='best_model.weights.h5', threshold=0.5):\n",
        "    uploaded = files.upload()\n",
        "    zip_file_path = list(uploaded.keys())[0]\n",
        "    directory_path = \"/content/input\"\n",
        "\n",
        "    if not os.path.exists(directory_path):\n",
        "        os.makedirs(directory_path)\n",
        "\n",
        "    # Extract the uploaded zip file\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(directory_path)\n",
        "    print(f\"Extracted files to '{directory_path}'.\")\n",
        "\n",
        "    extracted_folder_name = os.path.splitext(zip_file_path)[0]\n",
        "    directory_path = os.path.join(directory_path, extracted_folder_name)\n",
        "    print(f\"Updated directory path: {directory_path}\")\n",
        "\n",
        "    if not os.path.exists(directory_path):\n",
        "        print(f\"Error: Directory '{directory_path}' does not exist.\")\n",
        "        return\n",
        "\n",
        "    find_matching_images(directory_path, model_weights_path, threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QILL4F9LqTSU"
      },
      "outputs": [],
      "source": [
        "upload_and_test()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}